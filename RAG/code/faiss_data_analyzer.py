#!/usr/bin/env python3
"""
FAISS ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë°ì´í„° ë¶„ì„ê¸°
- FAISS API ì„œë²„ì—ì„œ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
- ê²€ìƒ‰ëœ ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ CLOVAì—ê²Œ ì „ë‹¬
- ì‹¤ì œ ë²¡í„° ê²€ìƒ‰ì„ í™œìš©í•œ RAG ì‹œìŠ¤í…œ
"""

import os
import sys
import json
import requests
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

from clova_chat_client import ClovaChatClient
from hybrid_vector_manager import HybridVectorManager

class FAISSDataAnalyzer:
    def __init__(self):
        self.chat_client = ClovaChatClient()
        self.vector_manager = HybridVectorManager()
        self.api_base_url = "http://localhost:8000"
        self.data_1_path = current_dir.parent / "data_1"
        self.data_1_path.mkdir(exist_ok=True)
    
    def check_api_server(self):
        """API ì„œë²„ ì—°ê²° í™•ì¸"""
        try:
            response = requests.get(f"{self.api_base_url}/health", timeout=5)
            if response.status_code == 200:
                data = response.json()
                print(f"âœ… FAISS API ì„œë²„ ì—°ê²° ì„±ê³µ")
                print(f"   ë²¡í„° ë¡œë“œ: {data.get('vectors_loaded', 0)}ê°œ")
                print(f"   FAISS ì¸ë±ìŠ¤: {'êµ¬ì¶•ë¨' if data.get('faiss_index_built') else 'ë¯¸êµ¬ì¶•'}")
                return True
            else:
                print(f"âŒ API ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ API ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ FAISS API ì„œë²„ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”: python faiss_vector_api.py")
            return False
    
    def search_vectors(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """FAISS API ì„œë²„ì—ì„œ ë²¡í„° ê²€ìƒ‰"""
        try:
            response = requests.post(
                f"{self.api_base_url}/search",
                json={"query": query, "top_k": top_k},
                timeout=120
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get("results", [])
            else:
                print(f"âŒ ê²€ìƒ‰ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return []
        except requests.exceptions.Timeout:
            print(f"âŒ ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ (120ì´ˆ)")
            return []
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def create_context_from_results(self, query: str, results: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if not results:
            return f"ì§ˆë¬¸: {query}\n\nê´€ë ¨ëœ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context = f"ì§ˆë¬¸: {query}\n\nê´€ë ¨ ë°ì´í„°:\n"
        
        for i, result in enumerate(results, 1):
            context += f"\n=== ê´€ë ¨ ë°ì´í„° {i} ===\n"
            context += f"ìœ ì‚¬ë„: {result['similarity']:.4f}\n"
            context += f"íƒ€ì…: {result['type']}\n"
            context += f"íŒŒì¼: {result['filename']}\n"
            
            if result.get('title'):
                context += f"ì œëª©: {result['title']}\n"
            
            context += f"ë‚´ìš©:\n{result['text_content']}\n"
        
        return context
    
    def run_analysis(self, rebuild_vectors: bool = False):
        """FAISS ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰"""
        print("\n" + "=" * 60)
        print("ğŸ” FAISS ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë¶„ì„")
        print("=" * 60)
        
        # 1. API ì„œë²„ ì—°ê²° í™•ì¸
        if not self.check_api_server():
            return False
        
        # 2. ë²¡í„° ì¬êµ¬ì¶• (í•„ìš”í•œ ê²½ìš°)
        if rebuild_vectors:
            print("\nğŸ“Š ë²¡í„° ì¬êµ¬ì¶• ì¤‘...")
            if not self.vector_manager.process_documents():
                print("âŒ ë²¡í„° ì¬êµ¬ì¶• ì‹¤íŒ¨!")
                return False
            print("âœ… ë²¡í„° ì¬êµ¬ì¶• ì™„ë£Œ")
        else:
            print("\nğŸ“Š ê¸°ì¡´ ë²¡í„° ì‚¬ìš© ì¤‘...")
            # ê¸°ì¡´ ë²¡í„° íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            vector_file = self.vector_manager.vector_dir / "hybrid_vectors.pkl"
            metadata_file = self.vector_manager.vector_dir / "hybrid_metadata.json"
            
            if not vector_file.exists() or not metadata_file.exists():
                print("âŒ ê¸°ì¡´ ë²¡í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
                print("ë²¡í„° ì¬êµ¬ì¶•ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                if not self.vector_manager.process_documents():
                    print("âŒ ë²¡í„° ì¬êµ¬ì¶• ì‹¤íŒ¨!")
                    return False
                print("âœ… ë²¡í„° ì¬êµ¬ì¶• ì™„ë£Œ")
            else:
                print("âœ… ê¸°ì¡´ ë²¡í„° íŒŒì¼ í™•ì¸ë¨")
        
        # 3. ë¶„ì„ ì§ˆë¬¸ ì •ì˜
        analysis_query = "ì§€ë‚œ 24ì‹œê°„ì˜ êµ­ë‚´ ì£¼ì‹ ì‹œì¥ì—ì„œ ê°€ì¥ ì´ìŠˆê°€ ëœ ì£¼ì‹ ì¢…ëª© 3ê°œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
        
        # 4. FAISS ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
        print("\nğŸ” FAISS ë²¡í„° ê²€ìƒ‰ ì¤‘...")
        search_results = self.search_vectors(analysis_query, top_k=10)
        
        if not search_results:
            print("âŒ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
        
        # 5. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = self.create_context_from_results(analysis_query, search_results)
        
        # 6. CLOVA ë¶„ì„
        print("\nğŸ¤– CLOVA ë¶„ì„ ì¤‘...")
        
        messages = [
            {
                "role": "system", 
                "content": "ë‹¹ì‹ ì€ ì£¼ì‹ ì‹œì¥ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ìŠˆê°€ ë˜ëŠ” ì¢…ëª©ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ì¢…ëª©ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ìŠˆê°€ ë˜ëŠ” ì¢…ëª©ëª… 3ê°œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
            },
            {
                "role": "user", 
                "content": context
            }
        ]
        
        try:
            response = self.chat_client.create_chat_completion(messages)
            
            # 7. ê²°ê³¼ ì €ì¥ (data_2 í´ë”ì— ì €ì¥)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            result_file = Path("/Users/Chris/Desktop/JH/MiraeassetNaver/RAG/data_2") / f"faiss_analysis_{timestamp}.json"
            
            result_data = {
                "timestamp": datetime.now().isoformat(),
                "query": analysis_query,
                "search_results_count": len(search_results),
                "result": response,  # stock_extractor.pyì™€ í˜¸í™˜ë˜ë„ë¡ ë³€ê²½
                "clova_response": response,
                "search_results": search_results
            }
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nâœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result_file}")
            print(f"ğŸ“ ì‘ë‹µ ê¸¸ì´: {len(response)} ë¬¸ì")
            
            return True
            
        except Exception as e:
            print(f"âŒ CLOVA ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    analyzer = FAISSDataAnalyzer()
    success = analyzer.run_analysis(rebuild_vectors=True)
    
    if success:
        print("\nğŸ‰ FAISS ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ!")
    else:
        print("\nâŒ FAISS ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë¶„ì„ ì‹¤íŒ¨!")

if __name__ == "__main__":
    main() 