#!/usr/bin/env python3
"""
í†µí•© ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- KRX ì¼ì¼ê±°ë˜ì •ë³´ ìˆ˜ì§‘
- ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘
- CLOVA ë¶„ì„ ë° ì£¼ì‹ ì¢…ëª© ì¶”ì¶œ
- Function Callingì„ í†µí•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
"""

from datetime import datetime
import subprocess
import time
import requests
import json
from pathlib import Path
from krx_api_client import KRXAPIClient
from naver_news_client import NaverNewsClient
from faiss_data_analyzer import FAISSDataAnalyzer
from stock_extractor import StockExtractor
from stock_news_collector import StockNewsCollector
from hybrid_vector_manager import HybridVectorManager
from clova_embedding import ClovaEmbeddingAPI
from clova_segmentation import ClovaSegmentationClient
from news_content_extractor import NewsContentExtractor

def start_faiss_api_server():
    """FAISS API ì„œë²„ ì‹œì‘"""
    print("\n" + "=" * 60)
    print("ğŸš€ FAISS API ì„œë²„ ì‹œì‘")
    print("=" * 60)
    
    # ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
    try:
        response = requests.get("http://localhost:8000/health", timeout=3)
        if response.status_code == 200:
            print("âœ… FAISS API ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return True
    except:
        pass
    
    # ì„œë²„ ì‹œì‘
    try:
        print("ğŸ”§ FAISS API ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        process = subprocess.Popen(
            ["python", "faiss_vector_api.py"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # ì„œë²„ ì‹œì‘ ëŒ€ê¸°
        for i in range(30):  # ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
            time.sleep(1)
            try:
                response = requests.get("http://localhost:8000/health", timeout=2)
                if response.status_code == 200:
                    print("âœ… FAISS API ì„œë²„ ì‹œì‘ ì™„ë£Œ")
                    return True
            except:
                continue
        
        print("âŒ FAISS API ì„œë²„ ì‹œì‘ ì‹¤íŒ¨")
        return False
        
    except Exception as e:
        print(f"âŒ FAISS API ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def start_vector_db1_api_server():
    """Vector DB1 FAISS API ì„œë²„ ì‹œì‘"""
    print("\n" + "=" * 60)
    print("ğŸš€ Vector DB1 FAISS API ì„œë²„ ì‹œì‘")
    print("=" * 60)
    
    # ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
    try:
        response = requests.get("http://localhost:8001/health", timeout=3)
        if response.status_code == 200:
            print("âœ… Vector DB1 FAISS API ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return True
    except:
        pass
    
    # ì„œë²„ ì‹œì‘
    try:
        print("ğŸ”§ Vector DB1 FAISS API ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        process = subprocess.Popen(
            ["python", "faiss_vector_db1_api.py"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # ì„œë²„ ì‹œì‘ ëŒ€ê¸°
        for i in range(30):  # ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
            time.sleep(1)
            try:
                response = requests.get("http://localhost:8001/health", timeout=2)
                if response.status_code == 200:
                    print("âœ… Vector DB1 FAISS API ì„œë²„ ì‹œì‘ ì™„ë£Œ")
                    return True
            except:
                continue
        
        print("âŒ Vector DB1 FAISS API ì„œë²„ ì‹œì‘ ì‹¤íŒ¨")
        return False
        
    except Exception as e:
        print(f"âŒ Vector DB1 FAISS API ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš€ í†µí•© ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
    print("ğŸ“… ì‹¤í–‰ ì‹œê°„:", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    print("=" * 60)
    
    # ===== ë‰´ìŠ¤ ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì • =====
    # ìµœì‹ ìˆœìœ¼ë¡œ 30ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘
    NEWS_CONFIG = {
        "query": "êµ­ë‚´ ì£¼ì‹ ì£¼ê°€",  # ê²€ìƒ‰ì–´
        "display": 100,           # ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜ (ìµœëŒ€ 100)
        "start": 1,               # ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜
        "sort": "date",           # ì •ë ¬ ë°©ë²• ("sim": ê´€ë ¨ë„ìˆœ, "date": ë‚ ì§œìˆœ)
        "filter_by_date": True,   # ë‚ ì§œ í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€
        "days_back": 1,           # ì§€ë‚œ ëª‡ ì¼ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ì§€ (1 = ì§€ë‚œ 1ì¼)
        "target_count": 30        # í•„í„°ë§ í›„ ëª©í‘œ ë‰´ìŠ¤ ê°œìˆ˜ (ìµœì‹ ìˆœ 30ê°œ)
    }
    
    print(f"ğŸ“° ë‰´ìŠ¤ ê²€ìƒ‰ ì„¤ì •: {NEWS_CONFIG}")
    
    # 1. KRX ì¼ì¼ê±°ë˜ì •ë³´ ìˆ˜ì§‘
    print("\n" + "=" * 60)
    print("ğŸ“ˆ KRX ì¼ì¼ê±°ë˜ì •ë³´ ìˆ˜ì§‘")
    print("=" * 60)
    
    krx_client = KRXAPIClient()
    krx_filename = krx_client.collect_and_save_daily_data()
    
    # 2. ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘
    print("\n" + "=" * 60)
    print("ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘")
    print("=" * 60)
    
    news_client = NaverNewsClient()
    
    # API ì •ë³´ í™•ì¸
    api_info = news_client.get_api_info()
    if not api_info['client_id_set'] or not api_info['client_secret_set']:
        print("âŒ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("NAVER_CLIENT_IDì™€ NAVER_CLIENT_SECRETì„ .env íŒŒì¼ì— ì„¤ì •í•˜ì„¸ìš”.")
        news_filename = None
    else:
        print("âœ… ë„¤ì´ë²„ API í‚¤ ì„¤ì • ì™„ë£Œ")
        print(f"ğŸ” '{NEWS_CONFIG['query']}' í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        
        # ì‚¬ìš©ì ì •ì˜ íŒŒë¼ë¯¸í„°ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
        success = news_client.get_custom_news(
            query=NEWS_CONFIG["query"],
            display=NEWS_CONFIG["display"],
            start=NEWS_CONFIG["start"],
            sort=NEWS_CONFIG["sort"],
            filter_by_date=NEWS_CONFIG["filter_by_date"],
            days_back=NEWS_CONFIG["days_back"],
            target_count=NEWS_CONFIG["target_count"]
        )
        
        if success:
            print("âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
            # íŒŒì¼ëª…ì€ naver_news_clientì—ì„œ ìë™ ìƒì„±ë¨
            news_filename = "ìˆ˜ì§‘ ì™„ë£Œ"
        else:
            print("âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
            news_filename = None
    
    # 3. ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“‹ ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    if krx_filename:
        print(f"âœ… KRX ë°ì´í„°: {krx_filename}")
    else:
        print("âŒ KRX ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    if news_filename:
        print(f"âœ… ë„¤ì´ë²„ ë‰´ìŠ¤: {news_filename}")
    else:
        print("âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    # 4. FAISS API ì„œë²„ ì‹œì‘
    if not start_faiss_api_server():
        print("âŒ FAISS API ì„œë²„ ì‹œì‘ ì‹¤íŒ¨ë¡œ ì¸í•´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    # 5. CLOVA ë¶„ì„ ë° ì£¼ì‹ ì¢…ëª© ì¶”ì¶œ
    print("\n" + "=" * 60)
    print("ğŸ¤– CLOVA ë¶„ì„ ë° ì£¼ì‹ ì¢…ëª© ì¶”ì¶œ")
    print("=" * 60)
    
    # FAISS ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë°ì´í„° ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = FAISSDataAnalyzer()
    
    # ì²« ë²ˆì§¸ ë°ì´í„° ë³€í™˜ ê²°ê³¼ í™•ì¸
    print("\n" + "=" * 60)
    print("ğŸ” ë°ì´í„° ë³€í™˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
    print("=" * 60)
    
    # KRX ë°ì´í„° ì²« ë²ˆì§¸ í•­ëª© ë³€í™˜ ê²°ê³¼ í™•ì¸
    print("\nğŸ“Š KRX ë°ì´í„° ì²« ë²ˆì§¸ í•­ëª© ë³€í™˜ ê²°ê³¼:")
    print("-" * 40)
    
    # KRX íŒŒì¼ ì°¾ê¸°
    import glob
    krx_files = glob.glob("/Users/Chris/Desktop/JH/MiraeassetNaver/RAG/data/krx_daily_trading_*.csv")
    if krx_files:
        import pandas as pd
        df = pd.read_csv(krx_files[0])
        print(f"ğŸ“„ íŒŒì¼: {krx_files[0]}")
        print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(df)}í–‰, {len(df.columns)}ì»¬ëŸ¼")
        
        # ì²« ë²ˆì§¸ ì¢…ëª© ì •ë³´ ì¶œë ¥
        if len(df) > 0:
            first_row = df.iloc[0]
            print(f"\nğŸ¢ ì²« ë²ˆì§¸ ì¢…ëª© ì •ë³´:")
            print(f"  ì¢…ëª©ëª…: {first_row.get('ISU_ABBRV', 'N/A')}")
            print(f"  ì¢…ëª©ì½”ë“œ: {first_row.get('ISU_CD', 'N/A')}")
            print(f"  ì‹œê°€: {first_row.get('TDD_OPNPRC', 'N/A')}")
            print(f"  ê³ ê°€: {first_row.get('TDD_HGPRC', 'N/A')}")
            print(f"  ì €ê°€: {first_row.get('TDD_LWPRC', 'N/A')}")
            print(f"  ì¢…ê°€: {first_row.get('TDD_CLSPRC', 'N/A')}")
            print(f"  ê±°ë˜ëŒ€ê¸ˆ: {first_row.get('ACC_TRDVAL', 'N/A')}")
            print(f"  ë“±ë½ë¥ : {first_row.get('FLUC_RT', 'N/A')}")
    
    # ë‰´ìŠ¤ ë°ì´í„° ì²« ë²ˆì§¸ í•­ëª© ë³€í™˜ ê²°ê³¼ í™•ì¸
    print("\nğŸ“° ë‰´ìŠ¤ ë°ì´í„° ì²« ë²ˆì§¸ í•­ëª© ë³€í™˜ ê²°ê³¼:")
    print("-" * 40)
    
    # ë‰´ìŠ¤ íŒŒì¼ ì°¾ê¸°
    news_files = glob.glob("/Users/Chris/Desktop/JH/MiraeassetNaver/RAG/data/naver_news_*.json")
    if news_files:
        import json
        with open(news_files[0], 'r', encoding='utf-8') as f:
            news_data = json.load(f)
        
        print(f"ğŸ“„ íŒŒì¼: {news_files[0]}")
        articles = news_data.get('items', [])
        print(f"ğŸ“Š ì „ì²´ ë‰´ìŠ¤: {len(articles)}ê°œ")
        
        if len(articles) > 0:
            first_article = articles[0]
            print(f"\nğŸ“° ì²« ë²ˆì§¸ ë‰´ìŠ¤ ì •ë³´:")
            print(f"  ì œëª©: {first_article.get('title', 'N/A')}")
            print(f"  ë‚´ìš©: {first_article.get('description', 'N/A')[:100]}...")
            print(f"  ë°œí–‰ì¼: {first_article.get('pubDate', 'N/A')}")
    
    print("\n" + "=" * 60)
    
    print("ğŸ” FAISS ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë¶„ì„ ì‹œì‘...")
    analysis_success = analyzer.run_analysis(rebuild_vectors=True)  # ë²¡í„° ì¬êµ¬ì¶•
    
    if analysis_success:
        print("âœ… FAISS ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ")
        
        # ì£¼ì‹ ì¢…ëª© ì¶”ì¶œ
        print("\nğŸ“Š ì£¼ì‹ ì¢…ëª© ì¶”ì¶œ ì‹œì‘...")
        extractor = StockExtractor()
        extraction_success = extractor.run_extraction()
        
        if extraction_success:
            print("âœ… ì£¼ì‹ ì¢…ëª© ì¶”ì¶œ ì™„ë£Œ")
            
            # 5. ìë™ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ (ì¶”ì¶œëœ ì¢…ëª©ëª… ì‚¬ìš©)
            print("\n" + "=" * 60)
            print("ğŸ“ˆ ìë™ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘")
            print("=" * 60)
            
            # stock_extractorì—ì„œ ì¶”ì¶œëœ ì¢…ëª©ëª…ì„ ê°€ì ¸ì™€ì„œ ìë™ ìˆ˜ì§‘
            extracted_stocks = extractor.get_extracted_stocks()
            
            if extracted_stocks:
                from stock_data_collector import StockDataCollector
                stock_collector = StockDataCollector()
                auto_collection_success = stock_collector.run_auto_collection(extracted_stocks)
                
                if auto_collection_success:
                    print("âœ… ìë™ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                else:
                    print("âŒ ìë™ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            else:
                print("âŒ ì¶”ì¶œëœ ì¢…ëª©ëª…ì´ ì—†ì–´ ìë™ ìˆ˜ì§‘ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            
            # 6. ê°œë³„ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘
            print("\n" + "=" * 60)
            print("ğŸ“° ê°œë³„ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘")
            print("=" * 60)
            
            news_stocks = extracted_stocks
            news_collector = StockNewsCollector()
            news_success = news_collector.run_collection(news_stocks)
            
            if news_success:
                print("âœ… ê°œë³„ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
            else:
                print("âŒ ê°œë³„ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
        else:
            print("âŒ ì£¼ì‹ ì¢…ëª© ì¶”ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    else:
        print("âŒ FAISS ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë¶„ì„ ì‹¤íŒ¨")
    
    # 7. data_1 í´ë” íŒŒì¼ë“¤ ì„ë² ë”©í•˜ì—¬ vector_db_1ì— ì €ì¥
    print("\n" + "=" * 60)
    print("ğŸ” data_1 í´ë” íŒŒì¼ë“¤ ì„ë² ë”©")
    print("=" * 60)
    
    try:
        # vector_db_1 ë””ë ‰í† ë¦¬ ìƒì„±
        vector_db_1_path = Path("/Users/Chris/Desktop/JH/MiraeassetNaver/RAG/vector_db_1")
        vector_db_1_path.mkdir(exist_ok=True)
        
        # data_1 í´ë”ìš© ë²¡í„° ë§¤ë‹ˆì € ìƒì„±
        class Data1VectorManager(HybridVectorManager):
            def __init__(self, data_dir: str):
                self.data_dir = Path(data_dir)
                self.vector_dir = vector_db_1_path
                self.vector_dir.mkdir(exist_ok=True)
                
                # CLOVA í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                self.embedding_client = ClovaEmbeddingAPI()
                self.segmentation_client = ClovaSegmentationClient()
                self.news_extractor = NewsContentExtractor()
                
                # ë²¡í„° ì €ì¥ì†Œ
                self.vectors_file = self.vector_dir / "hybrid_vectors.pkl"
                self.metadata_file = self.vector_dir / "hybrid_metadata.json"
                
                # ë²¡í„° ë°ì´í„° ë¡œë“œ
                self.vectors = []
                self.metadata = []
                self._load_vectors()
        
        # data_1 í´ë”ìš© ë²¡í„° ë§¤ë‹ˆì € ì´ˆê¸°í™”
        vector_manager = Data1VectorManager(
            data_dir="/Users/Chris/Desktop/JH/MiraeassetNaver/RAG/data_1"
        )
        
        print("ğŸ”§ data_1 í´ë” ë²¡í„° ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {vector_manager.data_dir}")
        print(f"ğŸ“ ë²¡í„° ë””ë ‰í† ë¦¬: {vector_manager.vector_dir}")
        
        # data_1 í´ë”ì˜ íŒŒì¼ë“¤ ì²˜ë¦¬
        print("\nğŸ“Š data_1 í´ë” íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
        success = vector_manager.process_documents()
        
        if success:
            print("âœ… data_1 í´ë” íŒŒì¼ë“¤ ì„ë² ë”© ì™„ë£Œ")
            print(f"ğŸ“Š ìƒì„±ëœ ë²¡í„°: {len(vector_manager.vectors)}ê°œ")
            print(f"ğŸ“Š ìƒì„±ëœ ë©”íƒ€ë°ì´í„°: {len(vector_manager.metadata)}ê°œ")
            
            # ë²¡í„° íŒŒì¼ ì €ì¥
            vector_file = vector_db_1_path / "hybrid_vectors.pkl"
            metadata_file = vector_db_1_path / "hybrid_metadata.json"
            
            import pickle
            with open(vector_file, 'wb') as f:
                pickle.dump(vector_manager.vectors, f)
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(vector_manager.metadata, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ë²¡í„° íŒŒì¼ ì €ì¥ ì™„ë£Œ: {vector_file}")
            print(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥ ì™„ë£Œ: {metadata_file}")
        else:
            print("âŒ data_1 í´ë” íŒŒì¼ë“¤ ì„ë² ë”© ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ data_1 í´ë” ì„ë² ë”© ì¤‘ ì˜¤ë¥˜: {e}")
    
    # 8. Vector DB1 FAISS API ì„œë²„ ì‹œì‘
    if not start_vector_db1_api_server():
        print("âŒ Vector DB1 FAISS API ì„œë²„ ì‹œì‘ ì‹¤íŒ¨ë¡œ ì¸í•´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    else:
        # 9. vector_db_1 ê¸°ë°˜ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
        print("\n" + "=" * 60)
        print("ğŸ“Š Vector DB1 ê¸°ë°˜ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ë³´ê³ ì„œ")
        print("=" * 60)
        
        try:
            from vector_db_1_analyzer import VectorDB1Analyzer
            analyzer = VectorDB1Analyzer()
            analysis_success = analyzer.run_analysis()
            
            if analysis_success:
                print("âœ… Vector DB1 ê¸°ë°˜ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
            else:
                print("âŒ Vector DB1 ê¸°ë°˜ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ Vector DB1 ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print("\nğŸ‰ í†µí•© ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 