#!/usr/bin/env python3
"""
í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""

import pandas as pd
import json
from pathlib import Path

def analyze_krx_tokens():
    """KRX ë°ì´í„° í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„"""
    print("=" * 60)
    print("ğŸ“Š KRX ë°ì´í„° í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„")
    print("=" * 60)
    
    # KRX CSV íŒŒì¼ ì½ê¸°
    csv_path = Path("../data/krx_daily_trading_20250725.csv")
    df = pd.read_csv(csv_path, encoding='utf-8-sig')
    
    print(f"ğŸ“ˆ ì›ë³¸ ë°ì´í„°: {len(df)}í–‰, {len(df.columns)}ì»¬ëŸ¼")
    print(f"ğŸ“ ì›ë³¸ íŒŒì¼ í¬ê¸°: {csv_path.stat().st_size:,} ë°”ì´íŠ¸")
    
    # í˜„ì¬ ì½”ë“œ ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
    text_parts = []
    
    # íŒŒì¼ëª… ì •ë³´
    text_parts.append(f"íŒŒì¼ëª…: krx_daily_trading_20250725")
    text_parts.append(f"ì´ {len(df)}í–‰, {len(df.columns)}ì»¬ëŸ¼")
    text_parts.append("")
    
    # KRX ë°ì´í„° íŠ¹ë³„ ì²˜ë¦¬
    text_parts.append("=== KRX ì¼ì¼ê±°ë˜ì •ë³´ (ë“±ë½ë¥  ìƒìœ„ 50%) ===")
    text_parts.append("")
    
    # ì „ì²´ ë°ì´í„°ì—ì„œ ê±°ë˜ëŒ€ê¸ˆ í•˜ìœ„ 60%ì™€ ë“±ë½ë¥  í•˜ìœ„ 60%ì—ì„œ ê²¹ì¹˜ëŠ” ì£¼ì‹ ì œì™¸
    df_processed = df.copy()
    
    # FLUC_RT ì»¬ëŸ¼ì„ ë“±ë½ë¥ ë¡œ ì‚¬ìš©
    df_processed['ë“±ë½ë¥ '] = df_processed['FLUC_RT']
    df_processed['ë“±ë½ë¥ _ì ˆëŒ€ê°’'] = df_processed['ë“±ë½ë¥ '].abs()
    
    print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(df_processed)}ê°œ ì¢…ëª©")
    
    # ê±°ë˜ëŒ€ê¸ˆ ê¸°ì¤€ í•˜ìœ„ 70% ì°¾ê¸°
    df_trading_value_sorted = df_processed.sort_values('ACC_TRDVAL', ascending=True)
    bottom_70_percent_trading = int(len(df_trading_value_sorted) * 0.7)
    low_trading_stocks = set(df_trading_value_sorted.head(bottom_70_percent_trading)['ISU_ABBRV'].tolist())
    
    # ë“±ë½ë¥  ê¸°ì¤€ í•˜ìœ„ 70% ì°¾ê¸° (ì ˆëŒ€ê°’ ê¸°ì¤€)
    df_change_rate_sorted = df_processed.sort_values('ë“±ë½ë¥ _ì ˆëŒ€ê°’', ascending=True)
    bottom_70_percent_change = int(len(df_change_rate_sorted) * 0.7)
    low_change_stocks = set(df_change_rate_sorted.head(bottom_70_percent_change)['ISU_ABBRV'].tolist())
    
    # ê²¹ì¹˜ëŠ” ì£¼ì‹ë“¤ ì°¾ê¸°
    overlapping_stocks = low_trading_stocks.intersection(low_change_stocks)
    
    print(f"ğŸ“Š ê±°ë˜ëŒ€ê¸ˆ í•˜ìœ„ 70%: {len(low_trading_stocks)}ê°œ ì¢…ëª©")
    print(f"ğŸ“Š ë“±ë½ë¥  í•˜ìœ„ 70%: {len(low_change_stocks)}ê°œ ì¢…ëª©")
    print(f"ğŸ“Š ê²¹ì¹˜ëŠ” ì¢…ëª©: {len(overlapping_stocks)}ê°œ")
    
    # ê²¹ì¹˜ëŠ” ì£¼ì‹ë“¤ì„ ì œì™¸í•œ ìµœì¢… í•„í„°ë§
    df_final_filtered = df_processed[~df_processed['ISU_ABBRV'].isin(overlapping_stocks)]
    
    print(f"ğŸ“Š ìµœì¢… í•„í„°ë§ ê²°ê³¼: {len(df_processed)}ê°œ â†’ {len(df_final_filtered)}ê°œ")
    
    # ê° ì¢…ëª©ë³„ë¡œ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
    processed_count = 0
    for idx, row in df_final_filtered.iterrows():
        stock_name = row.get('ISU_ABBRV', '')  # ì‹¤ì œ ì»¬ëŸ¼ëª…
        stock_code = row.get('ISU_CD', '')     # ì‹¤ì œ ì»¬ëŸ¼ëª…
        
        # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œë§Œ ì¶œë ¥
        if processed_count < 5:
            print(f"  ë””ë²„ê¹…: ì¢…ëª©ëª…='{stock_name}', ì¢…ëª©ì½”ë“œ='{stock_code}'")
        
        # ì¡°ê±´ ìˆ˜ì •: ì¢…ëª©ëª…ë§Œ ìˆìœ¼ë©´ ì²˜ë¦¬
        if stock_name:
            # ê°€ê²© ì •ë³´
            open_price = row.get('TDD_OPNPRC', 0)
            high_price = row.get('TDD_HGPRC', 0)
            low_price = row.get('TDD_LWPRC', 0)
            close_price = row.get('TDD_CLSPRC', 0)
            trading_value = row.get('ACC_TRDVAL', 0)
            change_rate = row.get('ë“±ë½ë¥ ', 0.0)
            
            # ì¢…ëª© ì •ë³´ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ êµ¬ì„±
            stock_info = f"ì¢…ëª©ëª…: {stock_name}, ì‹œê°€: {open_price}, ê³ ê°€: {high_price}, ì €ê°€: {low_price}, ì¢…ê°€: {close_price}, ê±°ë˜ëŒ€ê¸ˆ: {trading_value}, ë“±ë½ë¥ : {change_rate:.2f}"
            text_parts.append(stock_info)
            processed_count += 1
    
    print(f"ğŸ“Š ì‹¤ì œ ì²˜ë¦¬ëœ ì¢…ëª© ìˆ˜: {processed_count}ê°œ")
    
    text_parts.append("")
    text_parts.append(f"ì´ {len(df_final_filtered)}ê°œ ì¢…ëª©ì˜ ê±°ë˜ ì •ë³´ (ë“±ë½ë¥  ìƒìœ„ 50%)")
    
    # ìµœì¢… í…ìŠ¤íŠ¸ ìƒì„±
    final_text = "\n".join(text_parts)
    
    print(f"ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸ í¬ê¸°: {len(final_text):,} ë¬¸ì")
    print(f"ğŸ“Š ì˜ˆìƒ í† í° ìˆ˜: {int(len(final_text) * 1.3):,} í† í° (í•œê¸€ ê¸°ì¤€)")
    
    return len(final_text), len(df_final_filtered)

def analyze_news_tokens():
    """ë‰´ìŠ¤ ë°ì´í„° í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„ (30ê°œ ê¸°ì‚¬ ì‹œë®¬ë ˆì´ì…˜)"""
    print("\n" + "=" * 60)
    print("ğŸ“° ë‰´ìŠ¤ ë°ì´í„° í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„ (30ê°œ ê¸°ì‚¬)")
    print("=" * 60)
    
    # ë‰´ìŠ¤ JSON íŒŒì¼ ì½ê¸°
    json_path = Path("../data/naver_news_recent_3.json")
    with open(json_path, 'r', encoding='utf-8') as f:
        news_data = json.load(f)
    
    print(f"ğŸ“ˆ ì›ë³¸ ë°ì´í„°: {len(news_data.get('items', []))}ê°œ ë‰´ìŠ¤ ê¸°ì‚¬")
    print(f"ğŸ“ ì›ë³¸ íŒŒì¼ í¬ê¸°: {json_path.stat().st_size:,} ë°”ì´íŠ¸")
    
    # í˜„ì¬ ì½”ë“œ ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ (30ê°œ ê¸°ì‚¬ ì‹œë®¬ë ˆì´ì…˜)
    total_text_length = 0
    article_count = 0
    
    articles = news_data.get('items', [])
    
    # 30ê°œ ê¸°ì‚¬ë¡œ í™•ì¥ ì‹œë®¬ë ˆì´ì…˜
    expanded_articles = []
    for i in range(30):
        if i < len(articles):
            # ê¸°ì¡´ ê¸°ì‚¬ ì‚¬ìš©
            expanded_articles.append(articles[i])
        else:
            # ê¸°ì¡´ ê¸°ì‚¬ë¥¼ ë³µì œí•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜
            base_article = articles[i % len(articles)]
            simulated_article = {
                'title': f"{base_article.get('title', '')} (ê¸°ì‚¬ {i+1})",
                'description': f"{base_article.get('description', '')} - ì¶”ê°€ ë¶„ì„ ë‚´ìš©ì´ í¬í•¨ëœ í™•ì¥ëœ ë‰´ìŠ¤ ê¸°ì‚¬ì…ë‹ˆë‹¤.",
                'pubDate': base_article.get('pubDate', '')
            }
            expanded_articles.append(simulated_article)
    
    print(f"ğŸ“° í™•ì¥ëœ ë‰´ìŠ¤ ê¸°ì‚¬: {len(expanded_articles)}ê°œ")
    
    for i, article in enumerate(expanded_articles):
        # ê¸°ì‚¬ ì œëª©
        title = article.get('title', '')
        title_text = f"ì œëª©: {title}" if title else ""
        
        # ê¸°ì‚¬ ë‚´ìš© (ì„¤ëª…)
        description = article.get('description', '')
        if description:
            # HTML íƒœê·¸ ì œê±°
            import re
            clean_description = re.sub(r'<[^>]+>', '', description)
            content_text = f"ë‚´ìš©: {clean_description}"
        else:
            content_text = ""
        
        # ë°œí–‰ì¼
        pub_date = article.get('pubDate', '')
        date_text = f"ë°œí–‰ì¼: {pub_date}" if pub_date else ""
        
        # ì „ì²´ í…ìŠ¤íŠ¸
        article_text = "\n".join([title_text, content_text, date_text])
        total_text_length += len(article_text)
        article_count += 1
    
    print(f"ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì´ í¬ê¸°: {total_text_length:,} ë¬¸ì")
    print(f"ğŸ“Š ì˜ˆìƒ í† í° ìˆ˜: {int(total_text_length * 1.3):,} í† í° (í•œê¸€ ê¸°ì¤€)")
    print(f"ğŸ“° ì²˜ë¦¬ëœ ê¸°ì‚¬ ìˆ˜: {article_count}ê°œ")
    
    return total_text_length, article_count

def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    print("ğŸš€ í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    
    # KRX ë°ì´í„° ë¶„ì„
    krx_chars, krx_stocks = analyze_krx_tokens()
    
    # ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„
    news_chars, news_articles = analyze_news_tokens()
    
    # ì „ì²´ ë¶„ì„
    print("\n" + "=" * 60)
    print("ğŸ“‹ ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½")
    print("=" * 60)
    
    total_chars = krx_chars + news_chars
    total_tokens = total_chars * 1.3  # í•œê¸€ ê¸°ì¤€ í† í° ìˆ˜ ì¶”ì •
    
    print(f"ğŸ“Š KRX ë°ì´í„°: {krx_chars:,} ë¬¸ì ({krx_stocks}ê°œ ì¢…ëª©)")
    print(f"ğŸ“° ë‰´ìŠ¤ ë°ì´í„°: {news_chars:,} ë¬¸ì ({news_articles}ê°œ ê¸°ì‚¬)")
    print(f"ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸: {total_chars:,} ë¬¸ì")
    print(f"ğŸ¯ ì˜ˆìƒ í† í° ìˆ˜: {int(total_tokens):,} í† í°")
    
    # CLOVA API ì œí•œ í™•ì¸
    clova_limit = 120000  # 12ë§Œì ì œí•œ
    
    print(f"\nğŸ” CLOVA API ì œí•œ ë¶„ì„:")
    print(f"ğŸ“ CLOVA ì œí•œ: {clova_limit:,} ë¬¸ì")
    print(f"ğŸ“Š í˜„ì¬ ì‚¬ìš©ëŸ‰: {total_chars:,} ë¬¸ì")
    
    if total_chars > clova_limit:
        excess = total_chars - clova_limit
        print(f"âš ï¸ ì œí•œ ì´ˆê³¼: {excess:,} ë¬¸ì ({excess/clova_limit*100:.1f}% ì´ˆê³¼)")
        print(f"ğŸ’¡ ì²­í¬ ë¶„í•  í•„ìš”: {excess//100000 + 1}ê°œ ì²­í¬ë¡œ ë¶„í• ")
    else:
        remaining = clova_limit - total_chars
        print(f"âœ… ì œí•œ ë‚´ ì‚¬ìš©: {remaining:,} ë¬¸ì ì—¬ìœ ")
    
    print("\nğŸ‰ í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 